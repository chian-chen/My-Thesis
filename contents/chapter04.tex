% !TeX root = ../main.tex

\chapter{Proposed Method: Adaptive State-Space Design for Real-Time NVC Rate Control}

\section{System Overview}
% 這邊認真框架一下，目前進行的 Rate Control 的 input / output 為何，將 DCVC-RT 看做一個黑盒子做系統的化簡。
% 然後描述一下預計使用的 RLS (Recursive least squares) 基本概念

\subsection*{System Overview}

In this study, we treat the Neural Video Compressor (NVC) system, specifically DCVC-RT, as a non-linear time-variant system. To focus on the derivation of the rate control algorithm, the encoder is abstracted as a Single-Input Single-Output (SISO) black-box model. As shown in Fig.~\ref{fig:system_overview}, the system operates as a typical closed-loop control system.

\begin{figure}[!h]
    \centering
    \includegraphics[width=1.0\linewidth]{imgs/system.pdf}
    \caption{Overall architecture of the proposed rate control system. The DCVC-RT is treated as a black-box model. The controller determines the $QP_{final}$ based on the target bitrate and updates its internal model using the feedback loop after encoding.}
    \label{fig:system_overview}
\end{figure}

Let $t$ denote the index of the video frame and $X_t$ be the input raw image frame. For each frame, the objective of the Rate Control System is to determine a final Quantization Parameter ($QP_{final}$) based on the input target bitrate $R_{target}$, such that the actual number of bits generated by the encoder, $R_{real}$, is as close as possible to the budget. The input-output relationship of the system can be expressed as:
\begin{equation}
    R_{real, t}, \hat{X}_t = \mathcal{F}_{enc}(X_t, QP_{final, t} \mid \Theta_{net})
\end{equation}
where $\mathcal{F}_{enc}(\cdot)$ represents the encoding process of DCVC-RT, $\Theta_{net}$ denotes the fixed, pre-trained weights of the neural network, and $\hat{X}_t$ is the reconstructed image. Since we cannot modify $\Theta_{net}$ in real-time during the encoding process, $QP$ becomes the sole control variable.

As illustrated in Fig.~\ref{fig:system_overview}, our rate control system comprises three cascaded modules:
\begin{itemize}
    \item \textbf{1. Rate Allocator:} Responsible for \textbf{Budgeting} at both the Group of Pictures (GOP) and Frame levels. It translates the global bitrate target $R_{target}$ into a specific bit budget for the current frame, denoted as $Bits_{target}$.
    
    \item \textbf{2. Rate Estimator:} Maintains an internal \textbf{R-QP Model} to describe the relationship between quantization and bitrate. It takes the allocated $Bits_{target}$ as input and predicts the baseline quantization parameter, $QP_{raw}$. This module employs a recursive update mechanism to adapt to video content changes.
    
    \item \textbf{3. Post-processing:} Ensures the validity and stability of the control signal. It applies \textbf{Clipping} and \textbf{Smoothing} to the raw prediction $QP_{raw}$ to generate the final control command $QP_{final}$, preventing buffer overflow and temporal flickering.
\end{itemize}

After the encoding of frame $t$ is completed, the system utilizes a \textbf{Feedback Loop} to feed the actual generated bits $R_{real}$ back to the controller. This feedback triggers the \textbf{Update} of the budget status in the Rate Allocator and the \textbf{Parameter Update} in the Rate Estimator, thereby optimizing the decision-making for frame $t+1$.


\section{R-Q Modeling and Empirical Analysis}

\subsection*{Empirical R-Q Analysis via Exhaustive Search}
To achieve precise rate control in a closed-loop system, the primary task is to establish a mathematical model between the Quantization Parameter (QP) and bits per pixel ($R_{bpp}$). Unlike traditional video coding standards (e.g., H.264/HEVC) which often model in the $\lambda$-domain, we aim to identify the characteristic that best represents the essence of the DCVC-RT architecture. To eliminate interference from prediction errors, we employed an \textbf{Exhaustive Search} strategy.

During the encoding of test sequences, we forced the encoder to traverse all allowed integer QP values ($QP \in [0, 63]$), thereby obtaining the Ground Truth R-Q Curve for each frame globally. Based on these high-density data points, we evaluated four common candidate models:
\begin{itemize}
    \item Linear Model: $QP = a \cdot R_{bpp} + b$
    \item Power Model: $QP = a \cdot R_{bpp}^b$ (equivalent to $R = \alpha \cdot QP^\beta$)
    \item Exponential Model: $QP = a \cdot e^{b \cdot R_{bpp}}$
    \item Logarithmic Model: $QP = a \cdot \ln(R_{bpp}) + b$
\end{itemize}

Fig.~\ref{fig:rq_curve_fitting} presents the curve fitting results using the exhaustive data. Experimental results show that the \textbf{Logarithmic Model} exhibits the highest goodness-of-fit ($R^2$ score) across test frames. The Linear model tends to underestimate QP in the low bitrate range, while the Power model deviates in the high bitrate range. In contrast, the Log model accurately captures the characteristic of DCVC-RT where "bitrate decays exponentially as QP increases."

\begin{figure}[!h]
    \centering
    \includegraphics[width=1\linewidth]{imgs/qp_r_model.pdf}
    \caption{Empirical R-Q curve fitting based on exhaustive QP search data. The blue curve (Logarithmic model) demonstrates the highest fidelity to the actual data points across the entire bitrate range compared to other candidates.}
    \label{fig:rq_curve_fitting}
\end{figure}

\subsection*{Model Linearization and Objective Function}
Based on the empirical evidence, we adopt the Log-linear R-Q Model:
\begin{equation}
    QP_t = \alpha_t \cdot \ln(R_{bpp, t}) + \beta_t
\end{equation}
This finding distinguishes our work from recent NVC rate control research which often utilizes Power Models (requiring non-linear optimization). Our model possesses a critical mathematical advantage: \textbf{Parameter Linearization}.

The equation can be viewed as a standard linear equation $y_t = \mathbf{\theta}_t^T \mathbf{\phi}_t$, where the target variable $y_t$, parameter vector $\mathbf{\theta}_t$, and feature vector $\mathbf{\phi}_t$ are defined as:
\begin{equation}
    y_t = QP_t, \quad \mathbf{\theta}_t = \begin{bmatrix} \alpha_t \\ \beta_t \end{bmatrix}, \quad \mathbf{\phi}_t = \begin{bmatrix} \ln(R_{bpp, t}) \\ 1 \end{bmatrix}
\end{equation}

We define the rate control problem as an optimization problem minimizing the squared prediction error. The instantaneous loss function is:
\begin{equation}
    \mathcal{L}_t(\mathbf{\theta}_t) = \left( QP_{real, t} - \mathbf{\theta}_t^T \mathbf{\phi}_t \right)^2
\end{equation}
This linear structure allows us to avoid complex non-linear solvers and instead employ efficient recursive algorithms for online estimation.

\section{Adaptive Parameter Estimation via RLS}

\subsection*{Recursive Least Squares (RLS) Algorithm}
Due to the non-stationarity of video content, scene changes or fluctuations in complexity cause the optimal model parameters $\alpha_t$ and $\beta_t$ to vary over time. To adapt to this time-variant characteristic, we leverage the \textbf{Recursive Least Squares (RLS)} algorithm.

The RLS algorithm is particularly suitable here because, as established in the previous section, our system model is linear in its parameters. RLS minimizes the cumulative weighted error:
\begin{equation}
    \hat{\mathbf{\theta}}_t = \mathop{\arg\min}_{\mathbf{\theta}} \sum_{i=0}^{t} \lambda^{t-i} \mathcal{L}_i(\mathbf{\theta})
\end{equation}
where $\lambda \in (0, 1]$ is the forgetting factor. This factor balances the importance of historical data against current data, enabling the model to adapt quickly to scene changes.

Fig.~\ref{fig:rls_mechanism} illustrates the update mechanism. The specific steps for each frame $t$ are as follows:

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.95\linewidth]{imgs/RLS.pdf}
    \caption{Internal mechanism of the RLS Estimator. The model updates its parameter state $\mathbf{\theta}$ and covariance matrix $\mathbf{P}$ recursively based on the prediction error of the previous frame.}
    \label{fig:rls_mechanism}
\end{figure}

\begin{enumerate}
    \item \textbf{Calculate Gain Vector:}
    Based on the previous covariance matrix $\mathbf{P}_{t-1}$ and current feature vector $\mathbf{\phi}_t$, compute the Kalman Gain $\mathbf{k}_t$:
    \begin{equation}
        \mathbf{k}_t = \frac{\mathbf{P}_{t-1} \mathbf{\phi}_t}{\lambda + \mathbf{\phi}_t^T \mathbf{P}_{t-1} \mathbf{\phi}_t}
    \end{equation}
    In our implementation, we set $\lambda = 0.995$ for general P-frames to maintain stability while allowing adaptation.

    \item \textbf{Calculate Prediction Error (Priori Error):}
    Compute the error $e_t$ between the actually observed $QP_{used}$ and the value predicted by the previous state:
    \begin{equation}
        e_t = QP_{used, t} - \mathbf{\phi}_t^T \mathbf{\theta}_{t-1}
    \end{equation}

    \item \textbf{Update Model Parameters:}
    Correct the parameter estimate $\mathbf{\theta}_t$:
    \begin{equation}
        \mathbf{\theta}_t = \mathbf{\theta}_{t-1} + \mathbf{k}_t e_t
    \end{equation}

    \item \textbf{Update Covariance Matrix:}
    Update the matrix $\mathbf{P}$ for the next iteration:
    \begin{equation}
        \mathbf{P}_t = \frac{1}{\lambda} (\mathbf{P}_{t-1} - \mathbf{k}_t \mathbf{\phi}_t^T \mathbf{P}_{t-1})
    \end{equation}
\end{enumerate}

Through this recursive process, we obtain the optimal estimate $\mathbf{\theta}_t = [\alpha_t, \beta_t]$ immediately after each frame is encoded. 

\subsection*{Stability Analysis of Model Parameters}
Now that the RLS estimator is defined, we must verify whether the chosen Log-linear model is conducive to the convergence of this algorithm. The \textit{temporal stability} of model parameters is crucial for RLS; highly volatile parameters can lead to unstable Kalman gains and controller overshoot.

As illustrated in Fig.~\ref{fig:param_evolution}, we compared the parameter evolution of the Power Model ($QP = a \cdot R_{bpp}^b$) versus our Logarithmic Model over 600 frames. We selected two representative sequences: \textit{Beauty} (Low SI/TI) and \textit{ReadySteadyGo} (High TI).

\begin{figure*}[!t]
    \centering
    \includegraphics[width=1.0\linewidth]{imgs/qp_model_comp.pdf}
    \caption{Comparison of parameter evolution between Power Model (Left) and Log Model (Right). Top row: \textit{Beauty} (Low SI/TI); Bottom row: \textit{ReadySteadyGo} (High TI). The Log Model parameters ($\alpha$) exhibit stable periodicity within a predictable range ($10 \sim 20$), whereas the Power Model parameters fluctuate wildly ($100 \sim 550$) and lack clear patterns.}
    \label{fig:param_evolution}
\end{figure*}


The comparison reveals significant differences in parameter dynamics:
\begin{itemize}
    \item \textbf{Power Model (Left):} The multiplier parameter $a$ exhibits extreme variance and unpredictability. For \textit{Beauty}, $a$ fluctuates between 220 and 530; for \textit{ReadySteadyGo}, it drifts between 120 and 240. Such a wide and erratic dynamic range places a heavy tracking burden on the RLS estimator, making it prone to divergence or noise sensitivity.
    \item \textbf{Log Model (Right):} In contrast, our model's slope parameter $\alpha$ (blue line) demonstrates remarkable stability. Regardless of sequence complexity, $\alpha$ remains consistently within the range of $[10, 20]$. It exhibits a stable baseline with regular spikes corresponding to the periodic Refresh Frames, displaying a clear stationary pattern.
\end{itemize}

This predictable behavior of $\alpha$ in the Log domain validates our choice of model, confirming it as a robust foundation for the proposed RLS-based control system.


\section{Bitrate Allocation Strategy}

\subsection*{Analysis and Limitations of Existing Schemes}
Bit allocation serves as the decision-making core in closed-loop rate control. Its primary task is to translate the long-term target bitrate into specific bit budgets for individual frames.

The \textbf{Sliding Window-based allocation strategy}, originally established by Li et al. (IEEE TIP 2014) and recently adapted for Neural Video Coding by Liao et al. (ICASSP 2024), remains the industry standard for inter-frame bit regulation. This method relies on a fixed-size window to smooth traffic and has proven highly effective in traditional codecs (e.g., HEVC) and standard NVC approaches. Under typical configurations with short, fixed Group of Pictures (GOP) sizes (e.g., 16 or 32 frames), this strategy successfully balances budget fluctuations.

However, a critical misalignment arises when applying this standard strategy to the unique architecture of DCVC-RT. DCVC-RT operates on an "Infinite P-frame" structure, inserting periodic "Refresh Frames" (high-quality Intra-coded P-frames) to mitigate error propagation. These frames typically consume 3-5$\times$ the bits of normal frames.

Since the standard Sliding Window algorithm is not designed to anticipate such periodic, high-magnitude bursts within a continuous stream, it misinterprets the valid consumption of a Refresh Frame as a severe traffic overshoot. As illustrated in the bottom plot of Fig.~\ref{fig:allocator_comp}, the allocator "panics" upon encountering this spike (e.g., at Frame 64) and aggressively cuts the budget for subsequent frames. This results in a \textbf{post-refresh crash}—a sharp, unintended drop in quality immediately following the refresh—causing visible pumping artifacts.

\subsection*{Proposed Refresh-Aware Amortization Strategy}
To adapt the robust Sliding Window logic to the DCVC-RT structure, we propose a \textbf{Refresh-Aware Amortization Strategy}. The core idea is to decouple the budget planning from the immediate consumption of refresh frames. We define two mechanisms: \textit{Amortization} (saving up bits) and \textit{Virtual Feedback} (hiding the spike).

\vspace{0.5em}
\noindent \textbf{1. Amortization Scaling.}
We explicitly model the Refresh Period $L_{refresh}$. Assuming a Refresh Frame consumes $k$ times the bits of a normal frame (empirically $k \approx 3.0 \sim 5.0$), we introduce a scaling factor $\rho$ to levy a "bit tax" on normal frames:
\begin{equation}
    \rho = \frac{L_{refresh}}{ (L_{refresh} - 1) + k }
\end{equation}
The baseline target $T_{base}$ is adjusted to:
\begin{equation}
    T_{base}(t) = \begin{cases} k \cdot \rho \cdot R_{target}, & \text{if } t \in \text{Refresh} \\ 1 \cdot \rho \cdot R_{target}, & \text{if } t \in \text{Normal} \end{cases}
\end{equation}
This ensures that the extra cost of the refresh frame is amortized over the entire cycle, preventing budget depletion.

\vspace{0.5em}
\noindent \textbf{2. Virtual Feedback Mechanism.}
To prevent the underlying sliding window from reacting violently to the refresh spike, we normalize the feedback value. The allocator updates its history using a \textit{Virtual Bitrate} $R_{virt}$:
\begin{equation}
    R_{virt, t} = \begin{cases} R_{real, t} / k, & \text{if } t \in \text{Refresh} \\ R_{real, t}, & \text{if } t \in \text{Normal} \end{cases}
\end{equation}

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.7\linewidth]{imgs/allocator.png}
    \caption{Comparison of bit allocation stability around Refresh Frames. \textbf{Top (Baseline):} The standard sliding window reacts to the refresh spike (Frame 64) by aggressively cutting the budget, causing a visible "crash" (red box). \textbf{Bottom (Proposed):} Our strategy masks the spike, maintaining a stable baseline without post-refresh drops.}
    \label{fig:allocator_comp}
\end{figure}

Fig.~\ref{fig:allocator_comp} validates the effectiveness of this design. In the \textbf{Bottom} plot (Baseline), a significant dip in bitrate is observed immediately after the peaks (e.g., Frame 64, 192), indicating that the controller is punishing the subsequent frames for the refresh cost. In contrast, the \textbf{Top} plot (Proposed) maintains a stable baseline. The red dashed box highlights that even after a large refresh spike, the subsequent P-frames continue to receive a healthy bit budget, ensuring temporal consistency.

The complete allocation process is summarized in Algorithm~\ref{alg:refresh_aware}.

\begin{algorithm}
\caption{Refresh-Aware Amortization Bit Allocation}
\label{alg:refresh_aware}
\begin{algorithmic}[1]
\State \textbf{Input:} Target Bitrate $R_{target}$, Refresh Period $L_{refresh}$, Impact Factor $k$
\State \textbf{Initialize:} Rate Allocator $\mathcal{A}$ with sliding window size $SW$
\State \textbf{Calculate Scaling Factor:} $\rho \leftarrow L_{refresh} / ((L_{refresh}-1) + k)$
\For{each frame $t$}
    \State Determine frame type: $is\_refresh \leftarrow (t \pmod{L_{refresh}} == 0)$
    \If{$is\_refresh$}
        \State $T_{allocated} \leftarrow \mathcal{A}.allocate(k \cdot \rho \cdot R_{target})$
    \Else
        \State $T_{allocated} \leftarrow \mathcal{A}.allocate(1 \cdot \rho \cdot R_{target})$
    \EndIf
    \State \textbf{Encode} frame $t$ with budget $T_{allocated}$, get actual bits $R_{real}$
    \State \textbf{Feedback Update:}
    \If{$is\_refresh$}
        \State $\mathcal{A}.update(R_{real} / k)$ \Comment{Normalize to hide spike}
    \Else
        \State $\mathcal{A}.update(R_{real})$
    \EndIf
\EndFor
\end{algorithmic}
\end{algorithm}


\section{Dynamic Smoothing and Estimation}
% 對我 v15 的方法、過程中嘗試的一些平滑手段做詳細描述。

\subsection*{The Stability-Accuracy Trade-off}
Although the RLS estimator can capture changes in $R-QP$ model parameters in real-time, directly applying the raw predicted QP ($QP_{raw}$) to the encoder often leads to flickering artifacts. This is because the $R-Q$ relationship inherently contains noise, and neural encoders are extremely sensitive to minute QP changes. If we rely solely on instantaneous RLS predictions, QP may jump violently between adjacent frames. Conversely, using strong low-pass filtering (e.g., EMA with fixed coefficients) stabilizes the picture but makes the controller sluggish during scene cuts or traffic bursts, leading to buffer overflows or long-term bitrate drift. To break this "zero-sum game" between stability and accuracy, we propose a \textbf{Smart Smoothing Controller}.

\subsection*{Smart Smoothing Controller}
The core mechanism is the introduction of a \textbf{Safety Margin ($\epsilon$)} as a decision threshold. The controller monitors the bitrate error rate $E_t$ in real-time and dynamically switches between \textbf{Stable Mode} and \textbf{Emergency Mode}.

We define the error rate $E_t$ as the average relative error within the sliding window:
\begin{equation}
    E_t = \frac{|R_{real, t-1} - R_{target, t-1}|}{R_{target, t-1}}
\end{equation}

The smoothing logic is defined as:
\begin{equation}
    QP_{final, t} = \gamma_t \cdot QP_{final, t-1} + (1 - \gamma_t) \cdot QP_{raw, t}
\end{equation}
where the smoothing coefficient $\gamma_t$ is determined by the current error state:
\begin{equation}
    \gamma_t = \begin{cases} 0.8, & \text{if } E_t \le \epsilon \quad (\text{Stable Mode}) \\ 0.0, & \text{if } E_t > \epsilon \quad (\text{Emergency Mode}) \end{cases}
\end{equation}

\begin{itemize}
    \item \textbf{Stable Mode ($\gamma=0.8$):} When the error is within the acceptable range ($\epsilon=0.1$, i.e., 10\% error), we adopt a strong smoothing strategy. This acts as a low-pass filter, removing high-frequency noise from the RLS prediction to ensure gradual QP changes and visual consistency.
    \item \textbf{Emergency Mode ($\gamma=0.0$):} When the error exceeds the safety threshold (e.g., due to a scene cut causing model deviation), the system determines it is on the verge of losing control. The smoothing coefficient is immediately dropped to 0, bypassing the smoother and allowing the RLS prediction $QP_{raw}$ to act directly on the encoder. This grants the system a high response speed, pulling the bitrate back to the target line within 1-2 frames.
\end{itemize}

\section{Algorithm Summary}
% 整理整個算法寫成 Algorithm 的形式

Combining the above sections, we summarize the proposed \textbf{Refresh-Aware Log-RLS Rate Control} algorithm in Algorithm~\ref{alg:full_proposed}. This algorithm integrates periodic amortization allocation, hybrid cycle RLS estimation, and smart smoothing control into a complete closed-loop system.

\begin{algorithm}[!h]
\caption{Proposed Refresh-Aware Rate Control Algorithm}
\label{alg:refresh_aware_rc}
\begin{algorithmic}[1]
    \State \textbf{Input:} Target Bitrate $R_{target}$, Refresh Period $L_{refresh}$, Impact Factor $k$
    \State \textbf{Input:} Video Sequence $\{X_t\}$, Forgetting Factor $\lambda$, Safety Margin $\epsilon$
    \State \textbf{Initialize:} 
    \State \quad RLS States $\Theta_{refresh}, \Theta_{normal}$ with $[\alpha_0, \beta_0]$
    \State \quad Smoothing State $QP_{smooth} \leftarrow \text{None}$
    \State \quad Scaling Factor $\rho \leftarrow L_{refresh} / ((L_{refresh} - 1) + k)$

    \For{each frame $t = 1, 2, \dots, N$}
        \State \textit{// Step 1: Bitrate Allocation}
        \State Determine frame type: $type \in \{REFRESH, NORMAL\}$
        \If{$type == REFRESH$}
            \State $T_t \leftarrow \text{Allocator.get\_budget}(k \cdot \rho \cdot R_{target})$
            \State Select RLS Model: $\hat{\Theta}_t \leftarrow \Theta_{refresh}$
        \Else
            \State $T_t \leftarrow \text{Allocator.get\_budget}(1 \cdot \rho \cdot R_{target})$
            \State Select RLS Model: $\hat{\Theta}_t \leftarrow \Theta_{normal}$
        \EndIf
        
        \State \textit{// Step 2: Model Prediction (RLS)}
        \State Estimate raw QP: $QP_{raw} = \hat{\alpha} \cdot \ln(T_t) + \hat{\beta}$
        
        \State \textit{// Step 3: Smart Smoothing (Corrected)}
        \State Calculate recent error ratio $E_t$
        \If{$E_t > \epsilon$}
            \State $\gamma \leftarrow 0.0$ \Comment{Emergency Mode: Fast Response}
        \Else
            \State $\gamma \leftarrow 0.8$ \Comment{Stable Mode: Smoothing}
        \EndIf
        
        \If{$QP_{smooth}$ is None}
            \State $QP_{smooth} \leftarrow QP_{raw}$
        \Else
            \State $QP_{smooth} \leftarrow \gamma \cdot QP_{smooth} + (1-\gamma) \cdot QP_{raw}$ \Comment{Update Internal State}
        \EndIf
        \State $QP_{final} \leftarrow \text{Clip}(\text{Round}(QP_{smooth}), QP_{min}, QP_{max})$
        
        \State \textit{// Step 4: Encoding \& Update}
        \State Encode frame $X_t$ with $QP_{final}$, get actual bits $R_{real}$
        
        \State \textbf{Update RLS:}
        \State \quad Compute error $e = QP_{final} - (\hat{\alpha} \ln(R_{real}) + \hat{\beta})$
        \State \quad Update active state $\hat{\Theta}_t$ using RLS equations
        
        \State \textbf{Update Allocator:} \Comment{Virtual Feedback Logic}
        \If{$type == REFRESH$}
            \State $\text{Allocator.update}(R_{real} / k)$ 
        \Else
            \State $\text{Allocator.update}(R_{real})$
        \EndIf
    \EndFor
\end{algorithmic}
\label{alg:full_proposed}
\end{algorithm}